% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prediction_model.R
\name{build_cross_validation_classification_model}
\alias{build_cross_validation_classification_model}
\title{build an xgboost cross validation classification model with k-fold cross-validation}
\usage{
build_cross_validation_classification_model(
  target,
  features,
  folds,
  xgboost_params = list(booster = "gbtree", objective = "binary:logistic", subsample =
    0.7, max_depth = 3, colsample_bytree = 1, eta = 0.05, min_child_weight = 1, gamma =
    0, eval_metric = "auc"),
  nrounds = 1000
)
}
\arguments{
\item{target}{\itemize{
\item data.frame containing the patient id, target_class (0/1) and fold (number used to assigne to cross validation folds)
}}

\item{features}{\itemize{
\item data.frame containing patient id along with all other features to be used in classification model
}}

\item{folds}{\itemize{
\item number of cross-validation folds
}}

\item{xgboost_params}{\itemize{
\item parameters used for xgboost model training
}}

\item{nrounds}{\itemize{
\item number of training rounds
}}
}
\value{
a predictor, a list with the following elements
\itemize{
\item model - list of xgboost models, for each fold
\item train - data.frame containing the patients id, fold, target class and predicted value in training (each id was used in nfolds-1 for training)
\item test - data.frame containing the patients id, fold, target class and predicted value in testing (each id was tested once in the fold it was not used for training)
\item xgboost_params - the set of parameters used in xgboost
\item nrounds - number of training iterations conducted
}
}
\description{
build an xgboost cross validation classification model with k-fold cross-validation
}
\examples{
target <- data.frame(id = 1:1000, target_class = rep(c(0, 1), each = 500), sex = rep(0:1, 500))
features <- data.frame(id = 1:500, a = rnorm(500), b = rnorm(500)) \%>\%
    bind_rows(
        data.frame(id = 501:1000, a = rnorm(500, mean = 0.5, sd = 2), b = rnorm(500, mean = -0.5, sd = 2))
    )
predictor <- build_cross_validation_classification_model(target, features, folds = 3)
ggplot(predictor$test, aes(x = predict, colour = factor(target_class))) +
    geom_density() +
    theme_bw()
}
